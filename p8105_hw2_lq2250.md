p8105_hw2_lq2250
================
Lanlan_Qing
2024-09-25

# Load libraries

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(dplyr)
library(readxl)
```

# Problem 1

## Read and clean the data

``` r
data_nyc_transit = read_csv("data_hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                            na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select(line:entry, vending, ada)|>
  mutate(entry = 
           case_match(
             entry,
             "YES" ~ TRUE,
             "NO" ~ FALSE),
         across(route1:route11, as.character))|>
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    names_prefix = "route"
  )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
view(data_nyc_transit)
glimpse(data_nyc_transit)
```

    ## Rows: 20,548
    ## Columns: 10
    ## $ line              <chr> "4 Avenue", "4 Avenue", "4 Avenue", "4 Avenue", "4 A…
    ## $ station_name      <chr> "25th St", "25th St", "25th St", "25th St", "25th St…
    ## $ station_latitude  <dbl> 40.66040, 40.66040, 40.66040, 40.66040, 40.66040, 40…
    ## $ station_longitude <dbl> -73.99809, -73.99809, -73.99809, -73.99809, -73.9980…
    ## $ entrance_type     <chr> "Stair", "Stair", "Stair", "Stair", "Stair", "Stair"…
    ## $ entry             <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…
    ## $ vending           <chr> "YES", "YES", "YES", "YES", "YES", "YES", "YES", "YE…
    ## $ ada               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…
    ## $ route_number      <chr> "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "…
    ## $ route_name        <chr> "R", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, "R", NA…

## Q1:

*Write a short paragraph about this dataset – explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.
Are these data tidy?* <br>

**Answer:** <br>

1.variables: <br>

- line, station_name, station_latitude, station_longitude,
  entrance_type, entry, vending, ada, route_number, route_name

2.description of my data cleaning:<br>

- In the data cleaning process, I utilized the *janitor::clean_names()*
  to standardize column names, making them more manageable.

- I then use *select()* to select relevant columns, specifically those
  from line to entry, along with vending and ada compliant. The entry
  variable was transformed from character values (“YES” and “NO”) to
  logical values (TRUE and FALSE) using *case_match()*.

- Additionally, the route columns (from route1 to route11) were
  converted to numeric format using *mutate(across())*. Then I reshaped
  the data using *pivot_longer()* to transform the wide format of route
  columns into a long format, making the dataset more suitable for
  viewing.

- As a result of these steps, the dataset has dimensions of 20548 rows
  and 10 columns.

3.The resulting dataset is considered tidy as each variable name is
clear enough for analysis, easy-to-read, and reasonably categorized.
However, further data tidy process could be done depending on the use of
the dataset, such as separating data into several tables by different
lines/entrance types/station names etc..

## Q2:

*Answer the following questions using these data:*<br>

- *How many distinct stations are there? Note that stations are
  identified both by name and by line (e.g. 125th St 8th Avenue; 125st
  Broadway; 125st Lenox); the distinct function may be useful here.*<br>

**Coding**

``` r
station_type = data_nyc_transit |>
  count(line, station_name)
```

**Answer**

There are **465** distinct stations.

<br>

- *How many stations are ADA compliant?*

**Coding**

``` r
ada_compliant = data_nyc_transit |>
  distinct(line, station_name, ada) |>
  filter (ada == TRUE)
```

**Answer**

There are **84** stations that are ADA compliant.

<br>

- *What proportion of station entrances / exits without vending allow
  entrance?*

**Coding**

``` r
prop_no_entrance = data_nyc_transit |>
  count(vending)|>
  mutate(proportion = n/dim(data_nyc_transit)[1])
```

**Answer**

The proportion of station entrances without vendig allow entrance is
**0.0979657**.

<br>

## Q3:

*Reformat data so that route number and route name are distinct
variables. How many distinct stations serve the A train? Of the stations
that serve the A train, how many are ADA compliant?*

**Coding**

``` r
distinct_serve_A = data_nyc_transit |>
  distinct(line, station_name,route_name)|>
  filter(route_name == "A")

serve_A_ada = data_nyc_transit |>
  filter(route_name == "A")|>
  count(route_name, ada)
```

**Answer**

There are 60 distinct stations that serve A train. Of the stations that
serve the A train, 107 are ADA compliant.

# Problem 2

## Q1

**Read and clean the Mr. Trash Wheel sheet**

``` r
mr_trash_wheel = read_excel("data_hw2/202309 Trash Wheel Collection Data.xlsx", 
                            sheet = "Mr. Trash Wheel",
                            range = "A2:N586", 
                            na = c("NA", ".",""))|>
  janitor::clean_names()|>
  select(month:homes_powered)|>
  mutate(across(sports_balls, as.integer),
         year = as.double(year),
         wheel = "mr")
```

**Read and clean the Professor Trash Wheel Sheet**

``` r
professor_trash_wheel = read_excel("data_hw2/202309 Trash Wheel Collection Data.xlsx", 
                            sheet = "Professor Trash Wheel",
                            range = "A2:M108",
                            na = c("NA", ".",""))|>
  janitor::clean_names()|>
  select(month:homes_powered)|>
  mutate(sports_balls = NA, .after = "wrappers",
         across(sports_balls, as.integer),
         wheel = "professor")
```

**Read and clean the Gwynnda Trash Wheel Sheet**

``` r
gwynnda_trash_wheel = read_excel("data_hw2/202309 Trash Wheel Collection Data.xlsx", 
                            sheet = "Gwynnda Trash Wheel",
                            range = "A2:L157",
                            na = c("NA", ".",""))|>
  janitor::clean_names()|>
  select(month:homes_powered)|>
  mutate(sports_balls = NA, .after = "wrappers",
         across(sports_balls, as.integer)) |>
  mutate(glass_bottles = NA, .after = "cigarette_butts",
         wheel = "gwynnda")
```

**Combine three sheets**

``` r
trash_wheel_sheet = bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel)|>
  relocate(wheel)
```

## Q2

*Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in June of 2022?*<br>

1.The number of observations is **845**.

2.Key variables are: **wheel, month, year, date, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered**.

3.Total weight of trash collected by Professor Trash Wheel is:
**216.26** tons.

4.Total number of cigarette butts collected by Gwynnda in June of 2022
is **18120**.

# Problem 3

## Q1

**Data Cleaning**

``` r
bakers <- read_csv("data_hw2/gbb_datasets/bakers.csv", na = c("NA", ".",""))|>
  janitor::clean_names()|>
  separate(data = _, baker_name, into = c("baker_first", "baker_last"), sep = " ")|>
  relocate(baker_first)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes <- read_csv("data_hw2/gbb_datasets/bakes.csv", na = c("NA", ".",""))|>
  janitor::clean_names()|>
  rename(baker_first = baker)|>
  mutate(baker_first = replace(
    baker_first,
    baker_first =="\"Jo\"", "Jo"))|>
  relocate(baker_first)|>
  filter(baker_first != "Jo")|>
  add_row(baker_first = "Jo",series = 2, episode = 1,
                   signature_bake = NA, show_stopper = NA)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results <- read_csv("data_hw2/gbb_datasets/results.csv", na = c("NA", ".",""),
                    skip = 2)|>
  janitor::clean_names()|>
  rename(baker_first = baker)|>
  relocate(baker_first)|>
  filter(!is.na(result))|>
  add_row(baker_first = "Jo",series = 2, episode = 1,
                   technical = NA, result = "WD")
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Check dataset
view(bakers)
view(bakes)
view(results)

anti_join(bakes,bakers)
```

    ## Joining with `by = join_by(baker_first, series)`

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: baker_first <chr>, series <dbl>, episode <dbl>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(bakers, results)
```

    ## Joining with `by = join_by(baker_first, series)`

    ## # A tibble: 0 × 6
    ## # ℹ 6 variables: baker_first <chr>, baker_last <chr>, series <dbl>,
    ## #   baker_age <dbl>, baker_occupation <chr>, hometown <chr>

``` r
anti_join(results, bakes)
```

    ## Joining with `by = join_by(baker_first, series, episode)`

    ## # A tibble: 170 × 5
    ##    baker_first series episode technical result    
    ##    <chr>        <dbl>   <dbl>     <dbl> <chr>     
    ##  1 Joanne           2       1        11 IN        
    ##  2 Joanne           2       2        10 IN        
    ##  3 Joanne           2       3         1 IN        
    ##  4 Joanne           2       4         8 IN        
    ##  5 Joanne           2       5         6 IN        
    ##  6 Joanne           2       6         1 STAR BAKER
    ##  7 Joanne           2       7         3 IN        
    ##  8 Joanne           2       8         1 WINNER    
    ##  9 Diana            5       5        NA WD        
    ## 10 Diana            5       6        NA IN        
    ## # ℹ 160 more rows

**Create a single dataset**

``` r
bakers_infor = left_join(bakers, bakes)
```

    ## Joining with `by = join_by(baker_first, series)`

``` r
final_dataset = left_join(bakers_infor, results)|>
  mutate(baker = paste(baker_first, baker_last, by = " "))|>
  select(baker, baker_age, hometown, baker_occupation, series, episode,
         signature_bake, show_stopper, technical, result)
```

    ## Joining with `by = join_by(baker_first, series, episode)`

``` r
write.csv(final_dataset, file = file.path("data_hw2/gbb_datasets/", "merged_data.csv"))
```

## Q2

*Describe your data cleaning process, including any questions you have
or choices you made. Briefly discuss the final dataset.*<br>

- Simple data tidy: At the beginning, “read_csv()” was used to import
  three excel files data, and “janitor::clean_name()” was used to create
  analyzable variable names.

- Uniform variable names: Then, while viewing the datasets, variable
  names of bakers’ name were found to be different. Therefore, to easily
  combine the datasets, full-name of “baker_name” was separated into
  first_name and last_name, where first_name was taken use of, as only
  first names were shown in both “bakes” and “results” files.

- Incompatible value correction: Name format of “Jo” was found to be
  ““Jo”” in bakes. Quotes were deleted using “replace()”.

- Missing data created: While comparing datasets of “bakes” and
  “results” using “anti_join()”, candidate “Jo” wasn’t found in
  “results”, indicating the Withdraw (WD) status wasn’t recorded into
  the results dataset. To give more comprehensive data, “WD” of “Jo” was
  added using “add_rows()” to the first episode (series2-episode1) Jo
  supposed to attend. NA in records for other episodes.

- Missing data in bakes found: Two series(9-10) of bakes records and
  Joanne’s bakes record were missing, which leads to miss-match between
  “bakes” and the other two dataset.Problems of completing data
  happened.

- Merging datasets: Finally, dataset “bakers” was typed on the left side
  of “left_join()” function for matching and combining the other two
  datasets.Since the full name of candidates were preferred,
  “baker_first” and “baker_last” columns were combined by “paste()” and
  more reasonable orders of variables (from baker’s personal information
  to their attended episode and results of the competitions) were listed
  using “mutate()”.

## Q3

*Create a reader-friendly table showing the star baker or winner of each
episode in Seasons 5 through 10. Comment on this table – were there any
predictable overall winners? Any surprises?*

``` r
star_bakers_winners <- final_dataset |>
  filter(series >= 5 & series <= 10 & result %in% c("STAR BAKER", "WINNER")) |>
  select(series, episode, baker, result) |>
  arrange(series, episode)

knitr::kable(star_bakers_winners)
```

| series | episode | baker                | result     |
|-------:|--------:|:---------------------|:-----------|
|      5 |       1 | Nancy Birtwhistle    | STAR BAKER |
|      5 |       2 | Richard Burr         | STAR BAKER |
|      5 |       3 | Luis Troyano         | STAR BAKER |
|      5 |       4 | Richard Burr         | STAR BAKER |
|      5 |       5 | Kate Henry           | STAR BAKER |
|      5 |       6 | Chetna Makan         | STAR BAKER |
|      5 |       7 | Richard Burr         | STAR BAKER |
|      5 |       8 | Richard Burr         | STAR BAKER |
|      5 |       9 | Richard Burr         | STAR BAKER |
|      5 |      10 | Nancy Birtwhistle    | WINNER     |
|      6 |       1 | Marie Campbell       | STAR BAKER |
|      6 |       2 | Ian Cumming          | STAR BAKER |
|      6 |       3 | Ian Cumming          | STAR BAKER |
|      6 |       4 | Ian Cumming          | STAR BAKER |
|      6 |       5 | Nadiya Hussain       | STAR BAKER |
|      6 |       6 | Mat Riley            | STAR BAKER |
|      6 |       7 | Tamal Ray            | STAR BAKER |
|      6 |       8 | Nadiya Hussain       | STAR BAKER |
|      6 |       9 | Nadiya Hussain       | STAR BAKER |
|      6 |      10 | Nadiya Hussain       | WINNER     |
|      7 |       1 | Jane Beedle          | STAR BAKER |
|      7 |       2 | Candice Brown        | STAR BAKER |
|      7 |       3 | Tom Gilliford        | STAR BAKER |
|      7 |       4 | Benjamina Ebuehi     | STAR BAKER |
|      7 |       5 | Candice Brown        | STAR BAKER |
|      7 |       6 | Tom Gilliford        | STAR BAKER |
|      7 |       7 | Andrew Smyth         | STAR BAKER |
|      7 |       8 | Candice Brown        | STAR BAKER |
|      7 |       9 | Andrew Smyth         | STAR BAKER |
|      7 |      10 | Candice Brown        | WINNER     |
|      8 |       1 | Steven Carter-Bailey | STAR BAKER |
|      8 |       2 | Steven Carter-Bailey | STAR BAKER |
|      8 |       3 | Julia Chernogorova   | STAR BAKER |
|      8 |       4 | Kate Lyon            | STAR BAKER |
|      8 |       5 | Sophie Faldo         | STAR BAKER |
|      8 |       6 | Liam Charles         | STAR BAKER |
|      8 |       7 | Steven Carter-Bailey | STAR BAKER |
|      8 |       8 | Stacey Hart          | STAR BAKER |
|      8 |       9 | Sophie Faldo         | STAR BAKER |
|      8 |      10 | Sophie Faldo         | WINNER     |

**Comments on the table**

- Season 5: Surprisingly, the final winner was Nancy, while Richard won
  five games in episodes 2, 4, 7, 8, and 9 as a predictable final
  winner.

- Season 6: Nadiya was the predictable winner wining 4 games in episodes
  5, 8, 9, and 10 as the final winner.

- Season 7: Candice is predictable by wining four episodes in episodes
  2, 5, 8, and 10 as the final winner.

- Season 8: Steven and Sophie both won 3 times, making it hard to
  predict, and the overall winner was Sophie.

- Season 9: Rahul is the predictable winner winning three games in
  episodes 2, 3, and 10 as the final winner.

- Season 10: Steph is the predictable winner winning four games in
  episodes 4, 5, 6, and 8. However,surprisingly, the final winner was
  David, who didn’t win for any one time in the previous 9 episodes.

## Q4

*Import, clean, tidy, and organize the viewership data in viewers.csv.
Show the first 10 rows of this dataset. What was the average viewership
in Season 1? In Season 5?*

**Show the first 10 rows of this dataset.**

``` r
viewers_clean <- read_csv("data_hw2/gbb_datasets/viewers.csv",na = c("NA", ".","")) |>
  janitor::clean_names()|>
  pivot_longer(cols = series_1:series_10, 
               names_to = "series", 
               names_prefix = "series_", 
               values_to = "viewers")|>
  mutate(series = as.integer(series))|>
  arrange(series, episode)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewers_top <- viewers_clean |>
  head(10)|>
  print()
```

    ## # A tibble: 10 × 3
    ##    episode series viewers
    ##      <dbl>  <int>   <dbl>
    ##  1       1      1    2.24
    ##  2       2      1    3   
    ##  3       3      1    3   
    ##  4       4      1    2.6 
    ##  5       5      1    3.03
    ##  6       6      1    2.75
    ##  7       7      1   NA   
    ##  8       8      1   NA   
    ##  9       9      1   NA   
    ## 10      10      1   NA

**Calculate the average viewership**

``` r
avg_viewership_s1 <- viewers_clean |>
  filter(series == 1) |>
  summarise(avg_viewers = mean(viewers, na.rm = TRUE))

avg_viewership_s5 <- viewers_clean|>
  filter(series == 5) |>
  summarise(avg_viewers = mean(viewers, na.rm = TRUE))
```

**Answer**<br>

The average viewership in Season 1 is: **2.77**.<br>

The average viewership in Season 5 is: **10.0393**.

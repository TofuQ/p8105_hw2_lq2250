---
title: "p8105_hw2_lq2250"
author: "Lanlan_Qing"
date: "2024-09-25"
output: github_document
---
# Load libraries
```{r}
library(tidyverse)
library(dplyr)
library(readxl)
```
# Problem 1

## Read and clean the data
```{r}
data_nyc_transit = read_csv("data_hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                            na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select(line:entry, vending, ada)|>
  mutate(entry = 
           case_match(
             entry,
             "YES" ~ TRUE,
             "NO" ~ FALSE),
         across(route1:route11, as.character))|>
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    names_prefix = "route"
  )

view(data_nyc_transit)
glimpse(data_nyc_transit)

```

## Q1: 

*Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?* <br>

**Answer:** <br>

1.variables: <br>

 - `r colnames(data_nyc_transit)`
 
2.description of my data cleaning:<br>

 - In the data cleaning process, I utilized the *janitor::clean_names()* to standardize column names, making them more manageable. 
 
 - I then use *select()* to select relevant columns, specifically those from line to entry, along with vending and ada compliant. The entry variable was transformed from character values ("YES" and "NO") to logical values (TRUE and FALSE) using *case_match()*. 
 
 - Additionally, the route columns (from route1 to route11) were converted to numeric format using *mutate(across())*. Then I reshaped the data using *pivot_longer()* to transform the wide format of route columns into a long format, making the dataset more suitable for viewing.

 - As a result of these steps, the dataset has dimensions of `r dim(data_nyc_transit)[1]` rows and `r dim(data_nyc_transit)[2]` columns.
 
3.The resulting dataset is considered tidy as each variable name is clear enough for analysis, easy-to-read, and reasonably categorized. However, further data tidy process could be done depending on the use of the dataset, such as separating data into several tables by different lines/entrance types/station names etc..

## Q2:

*Answer the following questions using these data:*<br>

- *How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.*<br>

**Coding**
```{r}
station_type = data_nyc_transit |>
  count(line, station_name)
```

**Answer**

There are `r dim(station_type)[1]` distinct stations.

<br>

- *How many stations are ADA compliant?*

**Coding**
```{r}
ada_compliant = data_nyc_transit |>
  distinct(line, station_name, ada) |>
  filter (ada == TRUE)
```

**Answer**

There are `r dim(ada_compliant)[1]` stations that are ADA compliant.

<br>

- *What proportion of station entrances / exits without vending allow entrance?*

**Coding**
```{r}
prop_no_entrance = data_nyc_transit |>
  count(vending)|>
  mutate(proportion = n/dim(data_nyc_transit)[1])
```

**Answer**

The proportion of station entrances without vendig allow entrance is `r prop_no_entrance[1,3]`.

<br>

## Q3:

*Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?*

**Coding**
```{r}
distinct_serve_A = data_nyc_transit |>
  distinct(line, station_name,route_name)|>
  filter(route_name == "A")

serve_A_ada = data_nyc_transit |>
  filter(route_name == "A")|>
  count(route_name, ada)
```
**Answer**

There are 60 distinct stations that serve A train. Of the stations that serve the A train, 107 are ADA compliant.

# Problem 2

## Q1

**Read and clean the Mr. Trash Wheel sheet**

```{r}
mr_trash_wheel = read_excel("data_hw2/202309 Trash Wheel Collection Data.xlsx", 
                            sheet = "Mr. Trash Wheel",
                            range = "A2:N586", 
                            na = c("NA", ".",""))|>
  janitor::clean_names()|>
  select(month:homes_powered)|>
  mutate(across(sports_balls, as.integer),
         year = as.double(year),
         wheel = "mr")
```

**Read and clean the Professor Trash Wheel Sheet**

```{r}
professor_trash_wheel = read_excel("data_hw2/202309 Trash Wheel Collection Data.xlsx", 
                            sheet = "Professor Trash Wheel",
                            range = "A2:M108",
                            na = c("NA", ".",""))|>
  janitor::clean_names()|>
  select(month:homes_powered)|>
  mutate(sports_balls = NA, .after = "wrappers",
         across(sports_balls, as.integer),
         wheel = "professor")
```

**Read and clean the Gwynnda Trash Wheel Sheet**

```{r}
gwynnda_trash_wheel = read_excel("data_hw2/202309 Trash Wheel Collection Data.xlsx", 
                            sheet = "Gwynnda Trash Wheel",
                            range = "A2:L157",
                            na = c("NA", ".",""))|>
  janitor::clean_names()|>
  select(month:homes_powered)|>
  mutate(sports_balls = NA, .after = "wrappers",
         across(sports_balls, as.integer)) |>
  mutate(glass_bottles = NA, .after = "cigarette_butts",
         wheel = "gwynnda")
```

**Combine three sheets**

```{r}
trash_wheel_sheet = bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel)|>
  relocate(wheel)
```

## Q2

*Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?*<br>

1.The number of observations is **`r dim(trash_wheel_sheet)[1]`**.

2.Key variables are: **`r colnames(trash_wheel_sheet)`**.

3.Total weight of trash collected by Professor Trash Wheel is: **`r trash_wheel_sheet |> filter(wheel == "professor")|> select(weight_tons) |> sum()`** tons.

4.Total number of cigarette butts collected by Gwynnda in June of 2022 is **`r as.integer(trash_wheel_sheet |> filter((wheel == "gwynnda") & (month == "June") & (year == 2022)) |> select(cigarette_butts) |> sum())`**.

# Problem 3

## Q1

**Data Cleaning**
```{r}
bakers <- read_csv("data_hw2/gbb_datasets/bakers.csv", na = c("NA", ".",""))|>
  janitor::clean_names()|>
  separate(data = _, baker_name, into = c("baker_first", "baker_last"), sep = " ")|>
  relocate(baker_first)

bakes <- read_csv("data_hw2/gbb_datasets/bakes.csv", na = c("NA", ".",""))|>
  janitor::clean_names()|>
  rename(baker_first = baker)|>
  mutate(baker_first = case_match(
    baker_first,
    c("\"Jo\"") ~ "Jo",
    .default = baker_first
  ))|>
  relocate(baker_first)

results <- read_csv("data_hw2/gbb_datasets/results.csv", na = c("NA", ".",""),
                    skip = 2)|>
  janitor::clean_names()|>
  rename(baker_first = baker)|>
  relocate(baker_first)|>
  add_row(baker_first = "Jo",series = 2, episode = 1,
                   technical = NA, result = "WD")

view(bakers)
view(bakes)
view(results)

anti_join(bakers, bakes)
anti_join(bakers, results)
anti_join(bakes, results)

```

**Create a single dataset**

```{r}
bakers_infor = left_join(bakers, bakes)
final_dataset = left_join(bakers_infor, results)|>
  mutate(baker_full_name = paste(baker_first, baker_last, by = " "))|>
  select(baker_full_name, baker_age, hometown, baker_occupation, series, episode,
         signature_bake, show_stopper, technical, result)

write.csv(final_dataset, file = file.path("data_hw2/gbb_datasets/"), "merged_data.csv")
```

## Q2

*Describe your data cleaning process, including any questions you have or choices you made. Briefly discuss the final dataset.*<br>

- Simple data tidy: At the beginning, "read_csv()" was used to import three excel files data, and "janitor::clean_name()" was used to create analyzable variable names.

- Uniform variable names: Then, while viewing the datasets, variable names of bakers' name were found to be different. Therefore, to easily combine the datasets, full-name of "baker_name" was separated into first_name and last_name, where first_name was taken use of, as only first names were shown in both "bakes" and "results" files.

- Incompatible value correction: Name format of "Jo" was found to be ""Jo"" in bakes. Quotes were deleted using "case_match()".

- Missing data created: While comparing datasets of "bakes" and "results" using "anti_join()", candidate "Jo" wasn't found in "results", indicating the Withdraw (WD) status wasn't recorded into the results dataset. To give more comprehensive data, "WD" of "Jo" was added using "add_rows()" to the first episode (series2-episode1) Jo supposed to attend. NA in records for other episodes.

- Merging datasets: Finally, dataset "bakers" was typed on the left side of "left_join()" function for matching and combining the other two datasets.Since the full name of candidates were preferred, "baker_first" and "baker_last" columns were combined by "paste()" and more reasonable orders of variables (from baker's personal information to their attended episode and results of the competitions) were listed using "mutate()".

*Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10. Comment on this table – were there any predictable overall winners? Any surprises?*

```{r}
star_bakers_winners <- merged_data |>
  filter(series >= 5, series <= 10, result %in% c("STAR BAKER", "WINNER")) |>
  select(series, episode, baker) |>
  arrange(series, episode)

